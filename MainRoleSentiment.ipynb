{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EntityDataset import TrainDataset\n",
    "from LoadData import LoadData\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 02:18:33 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d512e799e1c94d359221fe58a578ad0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 02:18:33 INFO: Downloaded file to /Users/sankalpa/stanza_resources/resources.json\n",
      "2025-02-26 02:18:33 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-02-26 02:18:35 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| lemma     | combined_nocharlm         |\n",
      "| coref     | udcoref_xlm-roberta-lora  |\n",
      "| depparse  | combined_charlm           |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2025-02-26 02:18:35 INFO: Using device: cpu\n",
      "2025-02-26 02:18:35 INFO: Loading: tokenize\n",
      "2025-02-26 02:18:35 INFO: Loading: mwt\n",
      "2025-02-26 02:18:35 INFO: Loading: pos\n",
      "2025-02-26 02:18:37 INFO: Loading: lemma\n",
      "2025-02-26 02:18:37 INFO: Loading: coref\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/semeval/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2025-02-26 02:18:46 INFO: Loading: depparse\n",
      "2025-02-26 02:18:47 INFO: Loading: ner\n",
      "2025-02-26 02:18:49 INFO: Done loading processors!\n",
      "/var/folders/s7/c51hgx_90xj616ygyz402t680000gn/T/ipykernel_46994/1965112727.py:65: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df,pd.DataFrame({\n",
      "2025-02-26 02:19:12 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f819f280933e4a6e9915b61355863b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 02:19:12 INFO: Downloaded file to /Users/sankalpa/stanza_resources/resources.json\n",
      "2025-02-26 02:19:14 INFO: Loading these models for language: ru (Russian):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | syntagrus                |\n",
      "| pos       | syntagrus_charlm         |\n",
      "| lemma     | syntagrus_nocharlm       |\n",
      "| coref     | udcoref_xlm-roberta-lora |\n",
      "| depparse  | syntagrus_charlm         |\n",
      "| ner       | wikiner                  |\n",
      "========================================\n",
      "\n",
      "2025-02-26 02:19:14 INFO: Using device: cpu\n",
      "2025-02-26 02:19:14 INFO: Loading: tokenize\n",
      "2025-02-26 02:19:14 INFO: Loading: pos\n",
      "2025-02-26 02:19:16 INFO: Loading: lemma\n",
      "2025-02-26 02:19:19 INFO: Loading: coref\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/semeval/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2025-02-26 02:19:29 INFO: Loading: depparse\n",
      "2025-02-26 02:19:29 INFO: Loading: ner\n",
      "2025-02-26 02:19:35 INFO: Done loading processors!\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/semeval/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/semeval/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/semeval/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentiments = [\"Very Negative\", \"Negative\", \"Neutral\", \"Positive\", \"Very Positive\"]\n",
    "main_roles = [\"Protagonist\", \"Antagonist\", \"Innocent\"]\n",
    "sentiment_to_main_role = {\n",
    "    \"Very Negative\": \"Antagonist\",\n",
    "    \"Negative\": \"Antagonist\",\n",
    "    \"Neutral\": \"Innocent\",\n",
    "    \"Positive\": \"Protagonist\",\n",
    "    \"Very Positive\": \"Protagonist\"\n",
    "}\n",
    "languages = [\"EN\", \"RU\", \"PT\", \"HI\", \"BG\"]\n",
    "base_dir = \"train\"\n",
    "txt_file = \"subtask-1-annotations.txt\"\n",
    "\n",
    "ld = LoadData()\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['Language', 'Accuracy', 'Precision_Protagonist', 'Precision_Antagonist', 'Precision_Innocent', 'Recall_Protagonist', 'Recall_Antagonist', 'Recall_Innocent'])\n",
    "\n",
    "for lang_idx, lang in enumerate(languages):\n",
    "\n",
    "    total_instances = 0\n",
    "    match = 0\n",
    "    # Load data for each language\n",
    "    data = ld.load_data(base_dir, txt_file, lang)\n",
    "    train_dataset = TrainDataset(data, base_dir, language=lang, return_sentiment=True, coref=False)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['article_id', 'entity_mention', 'main_role', 'predicted_main_role'])\n",
    "\n",
    "    for idx, sample in enumerate(train_dataset):\n",
    "\n",
    "        index = np.argmax(sample['sent_sent'])\n",
    "\n",
    "        sent_main_role = sentiment_to_main_role[sentiments[index]]\n",
    "        true_main_role = sample[\"main_role\"]\n",
    "\n",
    "        if sent_main_role == true_main_role:\n",
    "            match += 1\n",
    "        \n",
    "        total_instances += 1\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([{\n",
    "            'article_id': sample['article_id'],\n",
    "            'entity_mention': sample['entity_mention'],\n",
    "            'main_role': true_main_role,\n",
    "            'predicted_main_role': sent_main_role\n",
    "        }])], ignore_index=True)\n",
    "        \n",
    "    accuracy = match / total_instances\n",
    "\n",
    "    # Calculate precision and recall for each main role\n",
    "    precision_dict = {}\n",
    "    recall_dict = {}\n",
    "\n",
    "    for role in main_roles:\n",
    "        true_positives = len(df[(df['main_role'] == role) & (df['predicted_main_role'] == role)])\n",
    "        predicted_positives = len(df[df['predicted_main_role'] == role])\n",
    "        actual_positives = len(df[df['main_role'] == role])\n",
    "        \n",
    "        precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "        recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "        \n",
    "        precision_dict[role] = precision\n",
    "        recall_dict[role] = recall\n",
    "\n",
    "    # Create a row for the CSV\n",
    "    results_df = pd.concat([results_df,pd.DataFrame({\n",
    "        'Language': [lang],\n",
    "        'Accuracy': [accuracy],\n",
    "        **{f'Precision_{role}': [precision_dict[role]] for role in main_roles},\n",
    "        **{f'Recall_{role}': [recall_dict[role]] for role in main_roles}\n",
    "        \n",
    "    })], ignore_index= True)\n",
    "    \n",
    "    # Append to CSV file, create if doesn't exist\n",
    "    \n",
    "\n",
    "    df.to_csv(f\"./sentiment_res/{lang}_sentiment.csv\", index=False)\n",
    "results_df.to_csv('./sentiment_res/evaluation.csv', header=not pd.io.common.file_exists('./sentiment_res/sentiment.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
